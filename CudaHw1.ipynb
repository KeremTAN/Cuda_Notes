{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 576,
     "status": "ok",
     "timestamp": 1732031649319,
     "user": {
      "displayName": "Kerem TAN",
      "userId": "05297536893078787516"
     },
     "user_tz": -180
    },
    "id": "ZuNlyi6BaVAo",
    "outputId": "84048caf-20a5-4fd8-f88c-62fe73502f0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Nov 19 15:54:08 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   46C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 8409,
     "status": "ok",
     "timestamp": 1732111139467,
     "user": {
      "displayName": "Kerem TAN",
      "userId": "05297536893078787516"
     },
     "user_tz": -180
    },
    "id": "Wi3OxndIa02g",
    "outputId": "864ff6e2-5c7b-4a62-d35a-852368d6dd02"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 276,
     "status": "ok",
     "timestamp": 1732111143314,
     "user": {
      "displayName": "Kerem TAN",
      "userId": "05297536893078787516"
     },
     "user_tz": -180
    },
    "id": "AiEpRfoWa9_B",
    "outputId": "9e18df71-5c31-44a0-8bab-5e10d067c993"
   },
   "outputs": [],
   "source": [
    "%load_ext nvcc4jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 3279,
     "status": "ok",
     "timestamp": 1732111558892,
     "user": {
      "displayName": "Kerem TAN",
      "userId": "05297536893078787516"
     },
     "user_tz": -180
    },
    "id": "clwFBKHpZhcx",
    "outputId": "7f6feac7-d7ef-4aa8-b87a-31608c4ff498"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector Init time : 0.017083 \n",
      "GPU Alloc & HtoD Data Transfer time : 0.181355 \n",
      "Sum Matrix time : 0.000307 \n",
      "Device to Host Data Transfer time : 0.002030 \n",
      "Validity Check is confirmed √\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "\n",
    "#include <cuda_runtime.h>\n",
    "#include <device_launch_parameters.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <iostream>\n",
    "#include <vector>\n",
    "#include <type_traits>\n",
    "\n",
    "#define gpuErrorCheck(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
    "\n",
    "inline void gpuAssert(cudaError_t ec, const char* file, int line, bool abort=true) {\n",
    "    if(ec != cudaSuccess) {\n",
    "        fprintf(stderr,  \"GPUassert: %s %s %d\\n\", cudaGetErrorString(ec), file, line);\n",
    "        if (abort) exit(ec);\n",
    "    }\n",
    "}\n",
    "\n",
    "__global__ void sum_matrix(int32_t* m1, int32_t* m2, int64_t* r, int size) {\n",
    "    int gid = threadIdx.x + blockIdx.x * blockDim.x +\n",
    "          (threadIdx.y + blockIdx.y * blockDim.y) * size;\n",
    "\n",
    "    if(gid < size*size) {\n",
    "       r[gid] = m1[gid] + m2[gid];\n",
    "    }\n",
    "\n",
    "}\n",
    "\n",
    "void print_time(const clock_t& start, const clock_t& end, const char* message) {\n",
    "    printf(message);\n",
    "    printf(\" time : %4.6f \\n\", (double)((double)(end-start)/CLOCKS_PER_SEC));\n",
    "}\n",
    "\n",
    "template <typename... Args>\n",
    "void device_free(Args*... pointers) {\n",
    "    gpuErrorCheck((cudaFree(pointers), ...));\n",
    "}\n",
    "\n",
    "int main (int argc, char** argv) {\n",
    "    const size_t size_x { 1024 }, size_y { 1024 };\n",
    "    const size_t total_size { size_y * size_x };\n",
    "    clock_t start{}, end{};\n",
    "\n",
    "    srand((unsigned)time(NULL));\n",
    "\n",
    "    // Cpu Data\n",
    "    start = clock();\n",
    "    std::vector<int32_t> matrix1(size_x * size_y, static_cast<int32_t>(rand() & 0xFF));\n",
    "    std::vector<int32_t> matrix2(size_x * size_y, static_cast<int32_t>(rand() & 0xFF));\n",
    "    std::vector<int64_t> results(size_x * size_y);\n",
    "    end = clock();\n",
    "    print_time(start, end, \"Vector Init\");\n",
    "\n",
    "    // Device Pointers\n",
    "    int32_t *device_matrix1{}, *device_matrix2{};\n",
    "    int64_t *device_results{};\n",
    "\n",
    "    // Device Allocation\n",
    "    start = clock();\n",
    "    gpuErrorCheck(cudaMalloc((int32_t**)&device_matrix1, sizeof(int32_t) * total_size));\n",
    "    gpuErrorCheck(cudaMalloc((int32_t**)&device_matrix2, sizeof(int32_t) * total_size));\n",
    "    gpuErrorCheck(cudaMalloc((int64_t**)&device_results, sizeof(int64_t) * total_size));\n",
    "\n",
    "    gpuErrorCheck(cudaMemcpy(device_matrix1, matrix1.data(), sizeof(int32_t) * total_size, cudaMemcpyHostToDevice));\n",
    "    gpuErrorCheck(cudaMemcpy(device_matrix2, matrix2.data(), sizeof(int32_t) * total_size, cudaMemcpyHostToDevice));\n",
    "    end = clock();\n",
    "    print_time(start, end, \"GPU Alloc & HtoD Data Transfer\");\n",
    "\n",
    "    dim3 block(32,32);\n",
    "    dim3 grid(size_x/block.x +1, size_y/block.y +1);\n",
    "\n",
    "\n",
    "    start = clock();\n",
    "    sum_matrix<<<grid, block>>>(device_matrix1, device_matrix2, device_results, size_x);\n",
    "    cudaDeviceSynchronize();\n",
    "    end = clock();\n",
    "    print_time(start, end, \"Sum Matrix\");\n",
    "\n",
    "    start = clock();\n",
    "    gpuErrorCheck(cudaMemcpy(results.data(), device_results, sizeof(int64_t) * matrix1.size(), cudaMemcpyDeviceToHost));\n",
    "    end = clock();\n",
    "    print_time(start, end, \"Device to Host Data Transfer\");\n",
    "\n",
    "    //Validty Check\n",
    "    for(int i=0; i<total_size; i++) {\n",
    "        if(results[i] != matrix1[i] + matrix2[i]) {\n",
    "          printf(\"!!! Validity Check is not confirmed !!!\\n\");\n",
    "          printf(\"result[%d] %d != %d\\n\", i, results[i], matrix1[i] + matrix2[i] );\n",
    "          device_free(device_matrix1, device_matrix2, device_results);\n",
    "          return -1;\n",
    "        }\n",
    "    }\n",
    "\n",
    "    device_free(device_matrix1, device_matrix2, device_results);\n",
    "    cudaDeviceReset();\n",
    "    printf(\"Validity Check is confirmed √\\n\");\n",
    "    return 0;\n",
    "}\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO6tDSp7Vf/dHAGK3sfZQlj",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
