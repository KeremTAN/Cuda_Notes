{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 595,
     "status": "ok",
     "timestamp": 1730986906849,
     "user": {
      "displayName": "Kerem TAN",
      "userId": "05297536893078787516"
     },
     "user_tz": -180
    },
    "id": "5O8BtBgsyIRL",
    "outputId": "ca7205f5-66b0-4066-b16e-d408cb144dbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Nov  7 13:41:46 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   48C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|  No running processes found                                                           |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 9430,
     "status": "ok",
     "timestamp": 1731154444656,
     "user": {
      "displayName": "Kerem TAN",
      "userId": "05297536893078787516"
     },
     "user_tz": -180
    },
    "id": "dn6j1CQayf_N",
    "outputId": "6e64c8d5-0f84-4d76-b7b6-8e72ffa91849"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1731154475516,
     "user": {
      "displayName": "Kerem TAN",
      "userId": "05297536893078787516"
     },
     "user_tz": -180
    },
    "id": "0N2ZuDg0zsCH",
    "outputId": "b7a3621c-d9e8-4d14-accf-f31d8183d567"
   },
   "outputs": [],
   "source": [
    "%load_ext nvcc4jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "usZSBaE22Rh5"
   },
   "outputs": [],
   "source": [
    "%%cuda\n",
    "\n",
    "#include <cuda_runtime.h>\n",
    "#include <device_launch_parameters.h>\n",
    "#include <stdio.h>\n",
    "\n",
    "__global__ void printDimentaionLocations() {\n",
    "    printf(\"ThreadIdx.X: %d ThreadIdx.Y: %d ThreadIdx.Z: %d \\n\",  threadIdx.x, threadIdx.y, threadIdx.z);\n",
    "    printf(\"BlockIdx.X: %d BlockIdx.Y: %d BlockIdx.Z: %d \\n\", blockIdx.x, blockIdx.y, blockIdx.z);\n",
    "    printf(\"GridIdx.X: %d GridIdx.Y: %d GridIdx.Z: %d \\n\", gridDim.x, gridDim.y, gridDim.z);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    printf(\"Welcome to Cuda\\n\");\n",
    "    int nx=4, ny=4, nz=4;\n",
    "\n",
    "    dim3 block(2, 2, 2);\n",
    "    dim3 grid(nx/block.x, ny/block.y, nz/block.z);\n",
    "\n",
    "\n",
    "    printDimentaionLocations<<<grid, block>>>();\n",
    "    cudaDeviceSynchronize();\n",
    "    cudaDeviceReset();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bcVZOLR2oi5P"
   },
   "outputs": [],
   "source": [
    "%%cuda\n",
    "\n",
    "#include <cuda_runtime.h>\n",
    "#include <device_launch_parameters.h>\n",
    "\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "__global__ void unique_id_threadIdx(int* input) {\n",
    "    int tid = threadIdx.x;\n",
    "    printf(\"ThreadIdx = %d | Value = %d \\n\", tid, input[tid]);\n",
    "}\n",
    "\n",
    "__global__ void unique_gid(int* input) {\n",
    "    int tid = threadIdx.x;\n",
    "    int offset = blockIdx.x * blockDim.x;\n",
    "    int gid = tid + offset;\n",
    "    printf(\"BlockIdx.x = %d | ThreadIdx = %d | Gid = %d | Value = %d \\n\",\n",
    "           blockIdx.x, tid, gid, input[gid]);\n",
    "    /*\n",
    "    16 elemanlı array\n",
    "    dim3 block(4,1,1);\n",
    "    dim3 grid(4,1,1);\n",
    "    */\n",
    "}\n",
    "\n",
    "__global__ void unique_gid_2d(int* input) {\n",
    "    int tid = threadIdx.x;\n",
    "    int block_offset = blockIdx.x * blockDim.x;\n",
    "    int row_offset = gridDim.x * blockDim.x * blockIdx.y;\n",
    "    int gid = tid + block_offset + row_offset;\n",
    "    printf(\"BlockIdx.X = %d | BlockIdx.Y = %d | ThreadIdx.X = %d | Gid = %d | Value = %d \\n\",\n",
    "           blockIdx.x, blockIdx.x, tid, gid, input[gid]);\n",
    "\n",
    "    /*\n",
    "    dim3 block(4,1,1);\n",
    "    dim3 grid(3,2,1);\n",
    "    */\n",
    "}\n",
    "\n",
    "__global__ void unique_gid_2d_2d(int* input) {\n",
    "    int tid = thradIdx.y * blockIdx.x + threadIdx.x;\n",
    "\n",
    "    int num_threads_in_a_block = blockDim.x * blockDim.y;\n",
    "    int block_offset = blockIdx.x * num_threads_in_a_block;\n",
    "\n",
    "    int num_threads_in_a_row = num_threads_in_a_block * gridDim.x;\n",
    "    int row_offset = num_threads_in_a_row * blockIdx.y;\n",
    "\n",
    "\n",
    "    int gid = tid + block_offset + row_offset;\n",
    "    printf(\"BlockIdx.X = %d | BlockIdx.Y = %d | ThreadIdx.X = %d | Gid = %d | Value = %d \\n\",\n",
    "           blockIdx.x, blockIdx.x, tid, gid, input[gid]);\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int array_size { 24 };\n",
    "    int byte_size { sizeof(int) * array_size };\n",
    "    int host_data[] = {12, 34, 342, 453 , 23, 56, 567, 789, 345, 578, 89, 44, 36, 67, 798, 57, 16, 57, 234, 56, 545, 67, 69, 24 };\n",
    "\n",
    "    for(const int& i : host_data) {\n",
    "        printf(\"%d \", i);\n",
    "    }\n",
    "\n",
    "    printf(\"\\n\\n\");\n",
    "\n",
    "    int* device_data;\n",
    "    cudaMalloc((void**)&device_data, byte_size);\n",
    "    cudaMemcpy(device_data, host_data, byte_size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    dim3 block(2,2,1);\n",
    "    dim3 grid(2,2,1);\n",
    "\n",
    "    unique_gid_2d <<<grid,block>>> (device_data);\n",
    "    cudaDeviceSynchronize();\n",
    "    cudaDeviceReset();\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 8697,
     "status": "ok",
     "timestamp": 1731065135674,
     "user": {
      "displayName": "Kerem TAN",
      "userId": "05297536893078787516"
     },
     "user_tz": -180
    },
    "id": "CIvSQNgewmqh",
    "outputId": "357dd954-8679-4787-f74c-3a30010351bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum array CPU execution time : 0.472199 \n",
      "Sum array GPU execution time : 0.006328 \n",
      "HtoD mem transfer time : 0.262671 \n",
      "DtoH mem transfer time : 0.085119 \n",
      "Total execution time : 0.354122 \n",
      "It is done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "// DERS 1.14 1.15 1.16\n",
    "#include <cuda_runtime.h>\n",
    "#include <device_launch_parameters.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "#include <cstring>\n",
    "\n",
    "\n",
    "// GPU ASSERT -------\n",
    "#define gpuErrorCheck(ans) { gpuAssert((ans), __FILE__, __LINE__); }\n",
    "\n",
    "inline void gpuAssert(cudaError_t errorCode, const char* file, int line, bool abort = true) {\n",
    "    if(errorCode != cudaSuccess) {\n",
    "        fprintf(stderr, \"GPUassert: %s %s %d\\n\", cudaGetErrorString(errorCode), file, line);\n",
    "        if(abort) exit(errorCode);\n",
    "    }\n",
    "   // else fprintf(stdout, \"GPUNotAssert: %s %s %d\\n\", cudaGetErrorString(errorCode), file, line); // Delete later\n",
    "}\n",
    "\n",
    "// ------- GPU ASSERT\n",
    "\n",
    "__global__ void sum_array_gpu(int* a, int* b, int* c, int size) {\n",
    "    int gid = blockIdx.x * blockDim.x + threadIdx.x ;\n",
    "\n",
    "    if(gid < size) {\n",
    "        c[gid] = a[gid] + b[gid] ;\n",
    "    }\n",
    "}\n",
    "\n",
    "void sum_array_cpu(int* a, int* b, int* c, int size) {\n",
    "    for(int i{}; i < size; i++) {\n",
    "        c[i] = a[i] + b[i] ;\n",
    "    }\n",
    "}\n",
    "\n",
    "void print_time(const clock_t& start, const clock_t& end, const char* message) {\n",
    "    printf(message);\n",
    "    printf(\" time : %4.6f \\n\", (double)((double)(end-start)/CLOCKS_PER_SEC));\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    int size { 1000000 };\n",
    "    int block_size { 256 };\n",
    "    cudaError error{};\n",
    "\n",
    "    int NO_BYTES = size * sizeof(int) ;\n",
    "\n",
    "    // Host Pointers\n",
    "    int *h_a{}, *h_b{}, *gpu_result{}, *h_c{};\n",
    "\n",
    "    h_a = (int*)malloc(NO_BYTES);\n",
    "    h_b = (int*)malloc(NO_BYTES);\n",
    "    gpu_result = (int*)malloc(NO_BYTES);\n",
    "    h_c = (int*)malloc(NO_BYTES);\n",
    "\n",
    "    time_t t;\n",
    "\n",
    "    srand((unsigned)time(&t));\n",
    "\n",
    "    for(int i{}; i < size; i++) h_a[i] = (int)(rand() & 0xFF);\n",
    "    for(int i{}; i < size; i++) h_b[i] = (int)(rand() & 0xFF);\n",
    "\n",
    "    clock_t cpu_start{}, cpu_end{};\n",
    "    cpu_start = clock();\n",
    "    sum_array_cpu(h_a, h_b, h_c, size);\n",
    "    cpu_end = clock();\n",
    "\n",
    "    memset(gpu_result, 0, NO_BYTES);\n",
    "\n",
    "    // Device Pointers\n",
    "    int *d_a{}, *d_b{}, *d_c{};\n",
    "\n",
    "    error = cudaMalloc((int**)&d_a, NO_BYTES);\n",
    "\n",
    "    if(error != cudaSuccess) {\n",
    "        fprintf(stderr, \"Error : %s \\n\", cudaGetErrorString(error));\n",
    "    }\n",
    "\n",
    "    gpuErrorCheck(cudaMalloc((int**)&d_b, NO_BYTES));\n",
    "    gpuErrorCheck(cudaMalloc((int**)&d_c, NO_BYTES));\n",
    "\n",
    "\n",
    "    clock_t htod_start{}, htod_end{};\n",
    "    htod_start = clock();\n",
    "    cudaMemcpy(d_a, h_a, NO_BYTES, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, h_b, NO_BYTES, cudaMemcpyHostToDevice);\n",
    "    htod_end = clock();\n",
    "\n",
    "\n",
    "\n",
    "    dim3 block(block_size);\n",
    "    dim3 grid((size/block.x) + 1); // + 1 eklenme sebebi bölme işleminden dolayı arada kaynayan veri olmasın diye\n",
    "\n",
    "    clock_t gpu_start{}, gpu_end{};\n",
    "    gpu_start  = clock();\n",
    "    sum_array_gpu<<<grid, block>>>(d_a, d_b, d_c, size);\n",
    "    cudaDeviceSynchronize();\n",
    "    gpu_end  = clock();\n",
    "\n",
    "\n",
    "    clock_t dtoh_start{}, dtoh_end{};\n",
    "    dtoh_start = clock();\n",
    "    cudaMemcpy(gpu_result, d_c, NO_BYTES, cudaMemcpyDeviceToHost); // gpu_result ile h_c elemanlarını karşılaştır buna da validation check de\n",
    "    dtoh_end = clock();\n",
    "\n",
    "\n",
    "    print_time(cpu_start, cpu_end, \"Sum array CPU execution\");\n",
    "    print_time(gpu_start, gpu_end, \"Sum array GPU execution\");\n",
    "    print_time(htod_start, htod_end, \"HtoD mem transfer\");\n",
    "    print_time(dtoh_start, dtoh_end, \"DtoH mem transfer\");\n",
    "    print_time(htod_start, dtoh_end, \"Total execution\");\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    cudaFree(d_c);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_a);\n",
    "\n",
    "    free(gpu_result);\n",
    "    free(h_b);\n",
    "    free(h_a);\n",
    "\n",
    "    printf(\"It is done\\n\");\n",
    "    return 0;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1612,
     "status": "ok",
     "timestamp": 1731155432523,
     "user": {
      "displayName": "Kerem TAN",
      "userId": "05297536893078787516"
     },
     "user_tz": -180
    },
    "id": "Z3GWdm3i0fAv",
    "outputId": "47575c73-4d9b-4f8b-dde5-207587a47216"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0: Tesla T4\n",
      " Number of multiprocessors  : 40\n",
      " Clock Rate                 : 1590000 khz\n",
      " Compute Capability         : 7.5\n",
      " Total amount of global mem : 14.75 GB\n",
      " Warp Size                  : 32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%cuda\n",
    "\n",
    "#include <cuda_runtime.h>\n",
    "#include <device_launch_parameters.h>\n",
    "#include <stdio.h>\n",
    "#include <stdlib.h>\n",
    "\n",
    "int device_query() {\n",
    "\n",
    "    int device_count{};\n",
    "    cudaGetDeviceCount(&device_count);\n",
    "\n",
    "    if(device_count == 0){\n",
    "        printf(\"There is no device which has supported by CUDA \\n\");\n",
    "        return -1;\n",
    "    }\n",
    "\n",
    "    int device_no{};\n",
    "    cudaDeviceProp iProp{};\n",
    "    cudaGetDeviceProperties(&iProp, device_no);\n",
    "\n",
    "    printf(\"Device %d: %s\\n\", device_no, iProp.name);\n",
    "    printf(\" Number of multiprocessors  : %d\\n\", iProp.multiProcessorCount);\n",
    "    printf(\" Clock Rate                 : %d khz\\n\", iProp.clockRate);\n",
    "    printf(\" Compute Capability         : %d.%d\\n\", iProp.major, iProp.minor);\n",
    "    printf(\" Total amount of global mem : %4.2f GB\\n\", iProp.totalGlobalMem / (1024.0f * 1024.0f *1024.0f));\n",
    "    printf(\" Warp Size                  : %d\\n\", iProp.warpSize);\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "    return device_query();\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyPSZBSWrsY+SrHviS18V7EY",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
